{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12137123",
   "metadata": {},
   "source": [
    "**CH3. 선형회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1f4a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.8097e-33, 1.3563e-19, 1.3563e-19],\n",
       "        [4.6201e-02, 4.6201e-02, 4.6201e-02]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#텐서 기본\n",
    "import torch\n",
    "X = torch.Tensor(2,3)#2X3크기의 텐서 생성, 원소는 임의의 난수\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457f2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.int64\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1,2,3],[4,5,6]])#원하는 값 직접입력 가능\n",
    "print(X)\n",
    "print(X.dtype)#텐서에 저장된 원소의 자료형\n",
    "print(X.data)#print(X)와 같음\n",
    "print(X.device)#어떤기기에 텐서를 올리는지\n",
    "print(X.requires_grad)#텐서에 대한 기울기를 저장할 것인지, default는 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1df294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.tensor(data=[2.0, 3.0], requires_grad=True)\n",
    "print(x_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f35b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 12.]) None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#torch.tensor는 dtype dafault가 int여서 float형으로 자료형을 변환해야 함. torch.Tensor는 float32\n",
    "x = torch.tensor(data=[2,3], dtype=torch.float32, requires_grad=True) \n",
    "y = x**2\n",
    "z = 2*y +3\n",
    "\n",
    "target = torch.tensor([3,4])\n",
    "loss = torch.sum(torch.abs(z-target))\n",
    "loss.backward()#연산 그래프를 따라가면서 기울기 계산\n",
    "\n",
    "print(x.grad, y.grad, z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ef64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn#다양한 신경망 layer, model 포함\n",
    "import torch.optim as optim#경사하강법 알고리즘\n",
    "import torch.nn.init as init#텐서의 초기값을 주기위해 필요한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be9e1b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 loss:7.070215702056885\n",
      "epoch10 loss:6.578315258026123\n",
      "epoch20 loss:6.087446212768555\n",
      "epoch30 loss:5.5978593826293945\n",
      "epoch40 loss:5.110666275024414\n",
      "epoch50 loss:4.627148151397705\n",
      "epoch60 loss:4.1467437744140625\n",
      "epoch70 loss:3.6722705364227295\n",
      "epoch80 loss:3.203761100769043\n",
      "epoch90 loss:2.7397966384887695\n",
      "epoch100 loss:2.286223888397217\n",
      "epoch110 loss:1.865540623664856\n",
      "epoch120 loss:1.496305227279663\n",
      "epoch130 loss:1.1971899271011353\n",
      "epoch140 loss:0.9883109927177429\n",
      "epoch150 loss:0.8715184926986694\n",
      "epoch160 loss:0.8212389945983887\n",
      "epoch170 loss:0.7986119389533997\n",
      "epoch180 loss:0.7866507768630981\n",
      "epoch190 loss:0.7811316847801208\n",
      "epoch200 loss:0.7790741324424744\n",
      "epoch210 loss:0.7786765694618225\n",
      "epoch220 loss:0.7785015106201172\n",
      "epoch230 loss:0.778419554233551\n",
      "epoch240 loss:0.7784190773963928\n",
      "epoch250 loss:0.778416633605957\n",
      "epoch260 loss:0.7784162759780884\n",
      "epoch270 loss:0.778415858745575\n",
      "epoch280 loss:0.7784155011177063\n",
      "epoch290 loss:0.7784150838851929\n",
      "epoch300 loss:0.7784146070480347\n",
      "epoch310 loss:0.7784141898155212\n",
      "epoch320 loss:0.7784140110015869\n",
      "epoch330 loss:0.7784140110015869\n",
      "epoch340 loss:0.7784138321876526\n",
      "epoch350 loss:0.7784138321876526\n",
      "epoch360 loss:0.778413712978363\n",
      "epoch370 loss:0.7784135937690735\n",
      "epoch380 loss:0.7784136533737183\n",
      "epoch390 loss:0.7784136533737183\n",
      "epoch400 loss:0.778413712978363\n",
      "epoch410 loss:0.7784135937690735\n",
      "epoch420 loss:0.7784136533737183\n",
      "epoch430 loss:0.778413712978363\n",
      "epoch440 loss:0.7784136533737183\n",
      "epoch450 loss:0.778413712978363\n",
      "epoch460 loss:0.7784135937690735\n",
      "epoch470 loss:0.7784136533737183\n",
      "epoch480 loss:0.7784136533737183\n",
      "epoch490 loss:0.778413712978363\n",
      "x의 weight는 1.9928969144821167, intercept는 2.9259636402130127\n"
     ]
    }
   ],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 500\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)#torch.tensor하면 안됨\n",
    "noise = init.normal_(torch.Tensor(num_data, 1), std=1)#평균은 defaut=0\n",
    "y = 2*x+3 #groudtruth function\n",
    "y_noise = y +noise#실제 관측 데이터는 noise가 포함되기 때문에 인위적인 noise를 y에 추가\n",
    "\n",
    "model = nn.Linear(1,1)\n",
    "loss_func = nn.L1Loss()#pred와 target의 차이의 절댓값의 합\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "#훈련\n",
    "label = y_noise\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad() #이전에 계산한 grad를 초기화, 누적하면 안되므로\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = loss_func(output, label)#loss 계산\n",
    "    loss.backward()#역전파(gradient 계산)\n",
    "    optimizer.step()#model parameter update\n",
    "    \n",
    "    if i%10 ==0:\n",
    "        print(f'epoch{i} loss:{loss.data}')#loss가 얼마인지 계산\n",
    "\n",
    "param_list = list(model.parameters())\n",
    "print(f'x의 weight는 {param_list[0].item()}, intercept는 {param_list[1].item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f8785",
   "metadata": {},
   "source": [
    "**CH4 인공신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e48ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69dfa40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 loss:77.72601318359375\n",
      "epoch100 loss:77.4529800415039\n",
      "epoch200 loss:77.12580871582031\n",
      "epoch300 loss:76.56979370117188\n",
      "epoch400 loss:75.60904693603516\n",
      "epoch500 loss:74.33014678955078\n",
      "epoch600 loss:72.26691436767578\n",
      "epoch700 loss:69.24293518066406\n",
      "epoch800 loss:65.29572296142578\n",
      "epoch900 loss:60.9739990234375\n",
      "epoch1000 loss:56.73688507080078\n",
      "epoch1100 loss:53.1046142578125\n",
      "epoch1200 loss:51.111385345458984\n",
      "epoch1300 loss:50.10088348388672\n",
      "epoch1400 loss:49.660133361816406\n",
      "epoch1500 loss:49.44694900512695\n",
      "epoch1600 loss:49.28504180908203\n",
      "epoch1700 loss:49.12825393676758\n",
      "epoch1800 loss:48.97956466674805\n",
      "epoch1900 loss:48.831947326660156\n",
      "epoch2000 loss:48.68457794189453\n",
      "epoch2100 loss:48.537723541259766\n",
      "epoch2200 loss:48.38978958129883\n",
      "epoch2300 loss:48.2381477355957\n",
      "epoch2400 loss:48.084320068359375\n",
      "epoch2500 loss:47.93023681640625\n",
      "epoch2600 loss:47.77267837524414\n",
      "epoch2700 loss:47.609615325927734\n",
      "epoch2800 loss:47.442726135253906\n",
      "epoch2900 loss:47.272586822509766\n",
      "epoch3000 loss:47.09580612182617\n",
      "epoch3100 loss:46.91088104248047\n",
      "epoch3200 loss:46.71605682373047\n",
      "epoch3300 loss:46.51279067993164\n",
      "epoch3400 loss:46.29971694946289\n",
      "epoch3500 loss:46.08251190185547\n",
      "epoch3600 loss:45.85422897338867\n",
      "epoch3700 loss:45.61542892456055\n",
      "epoch3800 loss:45.3663215637207\n",
      "epoch3900 loss:45.09977340698242\n",
      "epoch4000 loss:44.815059661865234\n",
      "epoch4100 loss:44.510459899902344\n",
      "epoch4200 loss:44.188568115234375\n",
      "epoch4300 loss:43.8427734375\n",
      "epoch4400 loss:43.46673583984375\n",
      "epoch4500 loss:43.06031799316406\n",
      "epoch4600 loss:42.61524200439453\n",
      "epoch4700 loss:42.13731384277344\n",
      "epoch4800 loss:41.61238098144531\n",
      "epoch4900 loss:41.021568298339844\n",
      "epoch5000 loss:40.36117172241211\n",
      "epoch5100 loss:39.62403106689453\n",
      "epoch5200 loss:38.82246780395508\n",
      "epoch5300 loss:37.97651290893555\n",
      "epoch5400 loss:37.100582122802734\n",
      "epoch5500 loss:36.20652389526367\n",
      "epoch5600 loss:35.404930114746094\n",
      "epoch5700 loss:34.68990707397461\n",
      "epoch5800 loss:34.008609771728516\n",
      "epoch5900 loss:33.346736907958984\n",
      "epoch6000 loss:32.69594192504883\n",
      "epoch6100 loss:32.084686279296875\n",
      "epoch6200 loss:31.539493560791016\n",
      "epoch6300 loss:31.0451602935791\n",
      "epoch6400 loss:30.59673500061035\n",
      "epoch6500 loss:30.190933227539062\n",
      "epoch6600 loss:29.838817596435547\n",
      "epoch6700 loss:29.513301849365234\n",
      "epoch6800 loss:29.223674774169922\n",
      "epoch6900 loss:28.938852310180664\n",
      "epoch7000 loss:28.690269470214844\n",
      "epoch7100 loss:28.47809600830078\n",
      "epoch7200 loss:28.26706314086914\n",
      "epoch7300 loss:28.034883499145508\n",
      "epoch7400 loss:27.782146453857422\n",
      "epoch7500 loss:27.483976364135742\n",
      "epoch7600 loss:27.11998748779297\n",
      "epoch7700 loss:26.579259872436523\n",
      "epoch7800 loss:25.60663604736328\n",
      "epoch7900 loss:23.202733993530273\n",
      "epoch8000 loss:22.321626663208008\n",
      "epoch8100 loss:21.525291442871094\n",
      "epoch8200 loss:20.740360260009766\n",
      "epoch8300 loss:19.966609954833984\n",
      "epoch8400 loss:19.207420349121094\n",
      "epoch8500 loss:18.45481300354004\n",
      "epoch8600 loss:17.682476043701172\n",
      "epoch8700 loss:16.880081176757812\n",
      "epoch8800 loss:16.063331604003906\n",
      "epoch8900 loss:15.232751846313477\n",
      "epoch9000 loss:14.368821144104004\n",
      "epoch9100 loss:13.49753189086914\n",
      "epoch9200 loss:12.609013557434082\n",
      "epoch9300 loss:11.690044403076172\n",
      "epoch9400 loss:10.820584297180176\n",
      "epoch9500 loss:10.016778945922852\n",
      "epoch9600 loss:9.256438255310059\n",
      "epoch9700 loss:8.538131713867188\n",
      "epoch9800 loss:7.857073783874512\n",
      "epoch9900 loss:7.215517044067383\n"
     ]
    }
   ],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 10000\n",
    "\n",
    "noise = init.normal_(torch.Tensor(num_data,1), std=1)\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -15, 15)\n",
    "y = (x**2)+3#비선형으로 한번 꼬아서\n",
    "y_noise = y+ noise\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(1,6),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(6,10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10,6),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(6,1))#4-layer fully-connected-layer\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "loss_array = []\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = loss_fn(output,y_noise)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_array.append(loss.data)#loss값만 필요하니까 loss.data사용\n",
    "    \n",
    "    if (i%100)==0:\n",
    "        print(f'epoch{i} loss:{loss.data}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4395e629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD5CAYAAADREwWlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkoUlEQVR4nO3deXwV5d338c8v+0LITghJWIMIshMFgrijqFVprUtrlbZaWluttr6eanv3vtu77fPctYtbtVZva6W2bnWl2qoIbiwiQRbZCXsgG0tI2LNczx9nsJEiOZBzMjkn3/frdV5n5po5J7/J4NfJNdfMmHMOERGJTDF+FyAiIidPIS4iEsEU4iIiEUwhLiISwRTiIiIRTCEuIhLB4oJZycy+B9wEOOBj4GtAPvAMkA0sAq53zh0+3vfk5OS4vn37tqdeEZEuZ9GiRTucc7nHWmZtjRM3swJgDjDEOXfAzJ4D/gFcArzonHvGzP4ALHXOPXy87yopKXFlZWUntREiIl2VmS1yzpUca1mw3SlxQLKZxQEpQCVwHvC8t3w6MKWddYqIyAlqM8Sdc9uA3wBbCIT3HgLdJ3XOuSZvtQqgIFxFiojIsbUZ4maWCVwB9AN6AanA5GB/gJlNM7MyMyurra096UJFROTfBdOdcgGw0TlX65xrBF4EJgAZXvcKQCGw7Vgfds496pwrcc6V5OYes19eREROUjAhvgUYZ2YpZmbA+cBK4G3gi946U4FXwlOiiIh8lmD6xBcQOIH5EYHhhTHAo8CdwPfNrJzAMMM/hrFOERE5hqDGiTvnfgL85KjmDcAZIa9IRESCFlSI++2lxRXsPdhEaXEO/XNSCfTqiIhIRIT4q0srmbW6BoCe3ZMoHZBNaXEOZ52SQ4+0JJ+rExHxT0SE+GNTS9iyaz9zy3cyt3wHb6+p4cXF24gxKB2Qw5RRBVw6LJ/khFi/SxUR6VBtXnYfSqG67L6lxbGysp43VlTx8pJtbN11gF7pSdx7zUjG9s8OQaUiIp1HKC6771RiYoyhBencceEg3vs/5/LUTWNJio/luscW8NSCLX6XJyLSYSIyxFszM0qLc3jpOxOYUJzDj176mLtfX40eAC0iXUHEh/gR6cnxPP7V07lubG8efmc9P355Oc0tCnIRiW4RcWIzWLExxi+mDKV7cjwPv7OeA43N/PaqERqSKCJRK6pCHALdK3dOPpWkuFjufWstBRnJ3HHhIL/LEhEJi6gL8SO+e34xlXsO8LvZ5QzJ787Fw/L9LklEJOSipk/8aGbGz6cMZXhhOj966WNq6g/6XZKISMhFbYgDxMfGcM/VI9l3uJn/+edqv8sREQm5qA5xgOIe3bjpzH68tHgbH23Z7Xc5IiIhFfUhDvDtc4vJTUvkV6/raFxEokuXCPFuiXF86+wBfLBhF4s27/K7HBGRkOkSIQ7wpTOKyEyJ58HZ5X6XIiISMl0mxFMS4vhqaT/eXlPLxh37/C5HRCQkukyIA1x7RhGxMcbTH+omWSISHbpUiOd1T2LS4DyeX1TBoaZmv8sREWm3NkPczAaZ2ZJWr3ozu93Mssxsppmt894zO6Lg9vry2N7s2neYt1bW+F2KiEi7BfO0+zXOuZHOuZHAGGA/8BJwFzDLOTcQmOXNd3oTinPITUtkxtJtfpciItJuJ9qdcj6w3jm3GbgCmO61TwemhLCusImNMS4dls/ba2qpP9jodzkiIu1yoiF+LfC0N53nnKv0pquAvJBVFWaXjejF4aYWZq6o9rsUEZF2CTrEzSwBuBz429HLXOAxOsd8AoOZTTOzMjMrq62tPelCQ2l07wwKMpL5+7LtfpciItIuJ3IkfjHwkXPuyOFrtZnlA3jvxzxT6Jx71DlX4pwryc3NbV+1IWJmXDy0J/PKd7LvUJPf5YiInLQTCfEv8a+uFIAZwFRveirwSqiK6gjnDe7B4eYW5pTv8LsUEZGTFlSIm1kqMAl4sVXzL4FJZrYOuMCbjxin980iLTGO2as01FBEIldQT/Zxzu0Dso9q20lgtEpEio+N4axBucxaXUNLiyMmRs/hFJHI06Wu2DzaBYN7sGPvIZZt2+N3KSIiJ6VLh/jZp/QA4P21nWPUjIjIierSIZ6VmsBpvbozd71ObopIZOrSIQ5wZnEOH22uY/9hDTUUkcjT5UN8QnEOh5tbWLhJz98UkcjT5UP89L5ZJMTGMFfjxUUkAnX5EE9OiGV0nwzmrFOIi0jk6fIhDoF+8ZWV9ezad9jvUkRETohCnEC/OMA8jVIRkQijEAeGFaSTlhSnLhURiTgKcSAuNoZx/bOZt36n36WIiJwQhbhnwoBstuzaz9Zd+/0uRUQkaApxT6nXLz5fR+MiEkEU4p6BPbqRm5aoS/BFJKIoxD1mRumAQL944GlzIiKdn0K8ldIB2dQ2HKK8Zq/fpYiIBEUh3krpgEC/uC7BF5FIoRBvpSgrhaKsZObq5KaIRAiF+FEmDMjhgw07aW5Rv7iIdH7BPig5w8yeN7PVZrbKzMabWZaZzTSzdd57ZriL7QilxTk0HGxiuR7ZJiIRINgj8fuB151zpwIjgFXAXcAs59xAYJY3H/HG9w88D1pDDUUkErQZ4maWDpwF/BHAOXfYOVcHXAFM91abDkwJT4kdKzctkUF5abroR0QiQjBH4v2AWuBPZrbYzB4zs1QgzzlX6a1TBeSFq8iOVlqczcJNuzjU1Ox3KSIixxVMiMcBo4GHnXOjgH0c1XXiAlfHHPNMoJlNM7MyMyurrY2Mp8qXDsjhYGMLi7fU+V2KiMhxBRPiFUCFc26BN/88gVCvNrN8AO+95lgfds496pwrcc6V5ObmhqLmsBvbP4sYg3kaLy4inVybIe6cqwK2mtkgr+l8YCUwA5jqtU0FXglLhT7onhTPsMIMjRcXkU4vLsj1bgX+amYJwAbgawT+B/Ccmd0IbAauDk+J/pgwIJtH39vA3kNNdEsM9tckItKxghpi6Jxb4nWJDHfOTXHO7XbO7XTOne+cG+icu8A5tyvcxXakCcU5NLU4Fm6Mqs0SkSijKzY/w5g+mSTExeg+KiLSqSnEP0NSfCxjemfqkW0i0qkpxI+jdEA2Kyvr2bXvsN+liIgck0L8OPTINhHp7BTixzGiMJ1uiXHM031URKSTUogfR1xsDGf0y1K/uIh0WgrxNpQOyGbjjn1srzvgdykiIv9GId6GCV6/uI7GRaQzUoi3YVBeGlmpCbqPioh0SgrxNsTEGBMH5vD2mhqamlv8LkdE5FMU4kGYfFpPdu9v5ENdgi8inYxCPAhnD8olKT6Gfy6v8rsUEZFPUYgHISUhjnNO6cHrK6poaTnmsy9ERHyhEA/SxcN6UttwSKNURKRTUYgH6aLTepKZEs+TH2zyuxQRkU8oxIOUFB/LNaf3ZubKarbu2u93OSIigEL8hEwt7UN8bAy/fmON36WIiAAK8ROSn57MtLP6M2PpdhZsUN+4iPhPIX6CvnX2APpkp/C9Z5dQt1/3GRcRfwUV4ma2ycw+NrMlZlbmtWWZ2UwzW+e9Z4a31M4hNTGO331pFLV7D/GNP5ex/3CT3yWJSBd2Ikfi5zrnRjrnSrz5u4BZzrmBwCxvvksYXpjBvdeMZNHm3Vz32AJ27D3kd0ki0kW1pzvlCmC6Nz0dmNLuaiLI54b34vfXjWbl9nqueHAury7brnuriEiHM+favgLRzDYCuwEHPOKce9TM6pxzGd5yA3YfmT/qs9OAaQC9e/ces3nz5tBV3wks2VrHnc8vY011A7lpiVw+ohelA7IZWZRBdrdEv8sTkShgZota9YJ8elmQIV7gnNtmZj2AmcCtwIzWoW1mu51zx+0XLykpcWVlZSdUfCRobnHMXFnNCx9V8M6aGhqbA7/TrNQE+uek0j83lf653eibnUrfnBR6Z6WQkhDnc9UiEimOF+JBJYlzbpv3XmNmLwFnANVmlu+cqzSzfKAmZBVHmNgYY/LQnkwe2pMDh5tZVlHHx9v2sL52H+tr9zJ7dS3PlVV86jO5aYn0yUqhd3YKfbL+Fe59slPJTIkn8MeNiMjxtRniZpYKxDjnGrzpC4GfATOAqcAvvfdXwllopEhOiGVs/2zG9s/+VPueA41s3rmPzTv3s2XX/k+m55Xv5MX6bZ9aNy0xjt7ZKfTNTqVPdor3SqVvdio90hKJiVHAi0hAMEfiecBL3pFhHPCUc+51M1sIPGdmNwKbgavDV2bkS0+OZ3hhBsMLM/5t2cHGZrbu2s/mnfvZvGs/W3buY9PO/aysrOeNFVU0tbpzYmJcDH2yU+idlUrf7BT65KTSJysQ+L0ykoiL1dB/ka6kzRB3zm0ARhyjfSdwfjiK6mqS4mMZmJfGwLy0f1vW1NxC5Z6DbPKO3Dd7Ab9l537mlNdysPFfI2LiYozCzGT6fHIE7wV8TgpFWSkkxsV25GaJSAfQ2bVOLi42hqKsQAhPHPjpZS0tjpqGQ590zWzeFQj4zTv38dHm3TQc+teFSDEGRVkpDMjtxoDcVIp7dPOmu5GZmtDBWyUioaIQj2AxMUbP9CR6pif9Wx+8c47d+xvZtHMfW3buZ0PtXtbv2Mf6mr3MKd/B4aZ/HcFnpSYwIDf1k1A/EvAFmcnEqv9dpFNTiEcpMyMrNYGs1ARG9/70yM/mFsf2ugOU1+5lfc3ewCiamr3MXFnNM/u2frJeUnwMg/LSGJzfnVN7pnFqfncG9+xOekp8R2+OiHyGoMaJh0q0jhOPJrv3HWbDjr2U1+xlbfVeVlfVs6qygV37/nWzr17pSYFgz09jaK90hhWmU5CRrGGRImHS7nHi0nVkpiYwJjWLMX2yPmlzzlHbcIiVlfWsrmpgVWU9qysbeGdtLc3eyJns1ASGF6Z7I3AC77lpumJVJNwU4tImM6NH9yR6dE/inEE9Pmk/2NjMmqoGllXUsbRiD8sq6nh3bS1HRkT2Sk9imBfoo3pnMKook+QEjZARCSWFuJy0pPhYRhRlMKIog+u9tn2HmlixvZ5lFXUs84L9jRXVQGAI5NCCdE7vm8npfbMo6ZtFlkbGiLSL+sQl7Pbsb+SjLbtZuGkXCzftYunWPRz27vhY3KMbp/fN4sziHCYUZ5ORolAXOVq7b4AVKgpxgUA3zPJte/hw0y7KNgXCveFgE2aBe7WfNTCHs07JZWRRBvG6AlVEIS6dW1NzC0sr9vD+ulreX7eDxVt20+KgW2IcEwfmcOFpeZw3KE9DG6XLUohLRNlzoJH563fy7tpaZq+uprr+ELExxrj+WVw4pCeThuTRKyPZ7zJFOoxCXCJWS4tj2bY9vLmiijdXVlNesxeAEUUZfH5kLy4b0UsP35CopxCXqLG+di9vrqjm70u3s7KynrgY4+xTcvn86AIuGJxHUryGMEr0UYhLVFpT1cCLiyt4efE2qusPkZ4cz1VjCvnKuD70zUn1uzyRkFGIS1RrbnHMX7+Tpxdu4Y3lgfuvn3VKLjeM68O5p/bQTbwk4inEpcuoqT/I0x9u5akPN1Ndf4g+2SlMO6s/V44uVFeLRCyFuHQ5jc0tzFxZzSPvrmdpxR5yuiVy45n9+Mq43qQlaaiiRBaFuHRZzjnmb9jJw++s5/11O8hMiec75xZz/fg+etKRRIzjhXjQl8OZWayZLTazV735fma2wMzKzexZM9P10tLpmBmlA3J48saxzLhlAkML0vnFa6s47zfv8tLiCjryIEYkHE7kmubbgFWt5u8G7nXOFQO7gRtDWZhIqA0vzODJG8fy5I1nkJkaz/eeXcrVj8xnTVWD36WJnLSgQtzMCoFLgce8eQPOA573VpkOTAlDfSIhN3FgLjO+cya/unI45TV7ueSB9/l//1jFvlbPJBWJFMEeid8H/AA48mDGbKDOOXfkX30FUBDa0kTCJybGuPr0ImbfcQ5XjSnk0fc2MPn+91i4aZffpYmckDZD3Mw+B9Q45xadzA8ws2lmVmZmZbW1tSfzFSJhk5mawC+vHM5z3xyPYVz9yHzufn31px4kLdKZBXMkPgG43Mw2Ac8Q6Ea5H8gwsyMPlSgEth3rw865R51zJc65ktzc3BCULBJ6Z/TL4h+3TeSakiIefmc9Ux6ay8Yd+/wuS6RNbYa4c+6HzrlC51xf4FpgtnPuOuBt4IvealOBV8JWpUgH6JYYxy+vHM7/3lDC9j0HuOx3c3htWaXfZYkcV3vuuH8n8H0zKyfQR/7H0JQk4q9JQ/J47bsTGZjXje889RE/eWU5h5qa/S5L5Jh0sY/IZzjc1MKvXl/NY3M2MrwwnYe+PJqirBS/y5IuKCQX+4h0NQlxMfz4c0N45PoxbNyxj0sfeJ/Zq6v9LkvkUxTiIm246LSevHbrRAozU/j6E2XcO3MtLS260lM6B4W4SBB6Z6fwws2lfGF0AffPWsfXpy+kbv9hv8sSUYiLBCs5IZbfXjWCn08ZytzyHVz24BxWbN/jd1nSxSnERU6AmXH9uD48+83xNDY5vvD7ebywqMLvsqQLU4iLnITRvTN59btnMqp3Bnf8bSn/+fJyXeUpvlCIi5yknG6J/OXGsUw7qz9PfrCZax6dT+WeA36XJV2MQlykHeJiY/jRJYP5/XWjWVvVwGW/m8PMlRqGKB1HIS4SApcMy+eVWyaQ0y2Rb/y5jO889RG1DYf8Lku6AIW4SIgU90hjxi1ncsekU5i5oppJ977LC4v09CAJL4W4SAglxMVw6/kD+cdtZzIgtxt3/G0pNzz+IZt0R0QJE4W4SBgU90jjb98cz39ffhqLt9Rx4b3vcc+bazhwWDfSktBSiIuESUyMMbW0L7PvOJtLhvXkgdnlXHDPu7y5okpdLBIyCnGRMOvRPYn7rh3FM9PGkZoYy7QnF/H1Jxaqi0VCQiEu0kHG9c/mte9O5MeXDmbhpt3qYpGQUIiLdKD42BhumtifWXeczcVeF8s5v3mbZxduoVl3RpSToBAX8UFe9yTuv3YUf/vWeHplJHPnCx9z8f3vMXt1tfrL5YQoxEV8dHrfLF68uZSHrxvN4aYWvv5EGV94eB4zV1brnuUSFD2eTaSTaGxu4ZmFW3nk3fVU7D7AKXnd+NbZA7hsRC/iY3W81ZUd7/FsbYa4mSUB7wGJQBzwvHPuJ2bWD3iGwEOSFwHXO+eOe5d8hbhI25qaW3h1WSUPv7OeNdUN9EpP4rpxfbi6pIjctES/yxMftDfEDUh1zu01s3hgDnAb8H3gRefcM2b2B2Cpc+7h432XQlwkeC0tjtmra/jTvI3MLd9JfKxxybB8rikpYmz/bGJjzO8SpYMcL8Tj2vqwC6T8Xm823ns54Dzgy177dOCnwHFDXESCFxNjXDAkjwuG5FFes5e/fLCZFxZV8MqS7fTsnsTlI3sxZWQBg/PTCBxrSVcUVJ+4mcUS6DIpBh4Cfg184Jwr9pYXAf90zg093vfoSFykfQ4cbuatVdW8vHgb766tpanFUdyjG5OG5HHB4DxGFmXoCD0Ktas75agvygBeAv4TeCKYEDezacA0gN69e4/ZvHnzCW+AiPy7XfsO89qy7fxzeRULNu6iucWR0y2Bcwf14PzBeYzvn016SrzfZUoIhCzEvS/7L+AAcCfQ0znXZGbjgZ865y463md1JC4SHnv2N/LO2hpmrarh7TU1NBxswgxO69Wd8f2zKR2Qw+n9suiW2GYPqnRC7T2xmQs0OufqzCwZeBO4G5gKvNDqxOYy59zvj/ddCnGR8GtsbuGjzbuZv2En89fvZPGWOg43txAbYwwrSGf8gGzG9stieGEGWakJfpcrQWhviA8ncOIylsDFQc85535mZv0JDDHMAhYDX3HOHfdRJgpxkY53sLH5k1Cft34nS7fW0eRdSNQrPYnTCtIZ2iudoQXdGVGUQU43DWPsbELandIeCnER/+071MTSrXWs2F7P8u17WL5tDxt27ONIFBRmJjOiKINRRRmMLMpgaEE6SfGx/hbdxbVriKGIRJfUxDhKi3MoLc75pG3foSZWbK9n6dY6lmytY8mWOl5bVglAbIxxas80Tu+bxYTiHMb2z6J7kk6YdhY6EheRY6ppOMjSrXtYsnU3S7bWsWjzbg42BvrWx/TO5JJhPbl4WD553ZP8LjXqqTtFRNrtUFMzi7fUMWfdDt5aVc3qqgbMAjfx+vqEflx0Wp4uOgoThbiIhFx5zV7+8XElL35Uwaad+xla0J07Jg3inEG5CvMQU4iLSNg0Nbfw8pLt3D9rLVt3HeDzowr4ny8M08nQEDpeiOv+liLSLnGxMXxxTCGzvn8O3590Ci8v2cYX/zCPmvqDfpfWJSjERSQkEuJi+O75A3nshhI21O7jhsc/ZP/hJr/LinoKcREJqfMH5/H760azuqqBe2eu9bucqKcQF5GQO2dQD64uKeSJeZuo3HPA73KimkJcRMLi1vMG0uLg8Tkb/S4lqinERSQsirJSmDQ4j5cWb6OpucXvcqKWQlxEwuaKkb3Ysfcw8zfs9LuUqKUQF5GwOffUHnRPiuP5RRV+lxK1FOIiEjZJ8bF8YXQhry6rZIGOxsNCIS4iYfW9SafQJyuFGx7/kKcWbKEjrxLvChTiIhJW6cnxPH9zKWf0y+JHL33MLU8tpv5go99lRQ2FuIiEXVZqAtO/dgZ3Tj6V11dUcekD77N4y26/y4oKCnER6RAxMcbN5wzguW+Op6UFrvrDfB6cvY7mFnWvtIdCXEQ61Jg+mfzjtolcPCyf37y5lmsemc/WXfv9LititRniZlZkZm+b2UozW2Fmt3ntWWY208zWee+Z4S9XRKJBenI8D1w7kvuuGcmaqgYuvv99XlhUoZOeJyGYI/Em4A7n3BBgHPAdMxsC3AXMcs4NBGZ58yIiQTEzpowq4J+3T2RIfnfu+NtSbnlqMXX7D/tdWkRpM8Sdc5XOuY+86QZgFVAAXAFM91abDkwJU40iEsUKM1N4eto4fjB5EG+sqGLyfe8zt3yH32VFjBPqEzezvsAoYAGQ55yr9BZVAXmhLU1EuorYGOPb5xTz0rcnkJIYy3WPLeAXr67kYGOz36V1ekGHuJl1A14AbnfO1bde5gIdWcfszDKzaWZWZmZltbW17SpWRKLbsMJ0Xrt1IteP68NjczYy5aG5rK6qb/uDXVhQIW5m8QQC/K/OuRe95mozy/eW5wM1x/qsc+5R51yJc64kNzc3FDWLSBRLTojl51OG8vhXS9ix9xCXPziXP87ZSIuGIh5TMKNTDPgjsMo5d0+rRTOAqd70VOCV0JcnIl3Veafm8frtZzGxOIefv7qSGx7/kKo9em7n0YI5Ep8AXA+cZ2ZLvNclwC+BSWa2DrjAmxcRCZmcbok8NrWE//v5oZRt3sXk+9/j9eWVbX+wC7GOHJdZUlLiysrKOuzniUj0WF+7l9ufWcLH2/Zw7elF/NdlQ0hJiPO7rA5hZouccyXHWqYrNkUkIgzI7cYLN5dy8zkDeLZsK597YA7LKur8Lst3CnERiRgJcTHcOflU/nrTWPYfbuYLv5/Hw++s79InPRXiIhJxSgfk8PrtE7nwtDzufn011z++gNqGQ36X5QuFuIhEpIyUBB768mh++YVhlG3azSUPvM+89V3vSk+FuIhELDPj2jN688otE0hLiuMrjy3ggVld6/a2CnERiXin9uzO3285k8tH9OKemWuZ+viHXaZ7RSEuIlEhNTGOe68Zyd1XDmPhpl1c8sD7zF8f/Q9nVoiLSNQwM645vTcvf2cCaYlxXPfYBzz0dnlU36dcIS4iUWdwfndm3Homlw7vxa/fWMO3/rKIvYea/C4rLBTiIhKVuiXG8cC1I/nxpYN5a1UNVzw4h/W1e/0uK+QU4iIStcyMmyb258kbz2D3/kaueHAub66o8ruskFKIi0jUKx2Qw99vPZP+ualMe3IR97y5Jmqu8lSIi0iXUJCRzHPfHM9VYwp5YHY5N05fyJ4DjX6X1W4KcRHpMpLiY/nVF4fziylDmVO+gykPzWVddYPfZbWLQlxEuhQz4yvj+vD0N8ax91ATUx6ay+vLI7efXCEuIl1SSd8s/n7LmQzMS+Nbf4ncfnKFuIh0WT3Tk3j2m+O4uiTQT/6NP5dRfzCy+skV4iLSpSXGxXL3lcP52RWn8e7aWqY8NJfymsgZT64QF5Euz8y4YXxf/nrTWOoPNDLlobnMXFntd1lBCeZp94+bWY2ZLW/VlmVmM81snfeeGd4yRUTCb2z/bGbcEhhP/o0/l3H/W+s6fT95MEfiTwCTj2q7C5jlnBsIzPLmRUQiXi9vPPmVowu59621fOsvi2joxP3kbYa4c+49YNdRzVcA073p6cCU0JYlIuKfpPhYfnPVcH5y2RBmra7h8gfnsmRrnd9lHdPJ9onnOecqvekqIC9E9YiIdApmxtcm9OPpb4zjcFMLVz48j9/NWkdTc4vfpX1Ku09susCNej+z08jMpplZmZmV1dbWtvfHiYh0qDP6ZfGP2ybyueH5/HbmWq559AO27Nzvd1mfONkQrzazfADvveazVnTOPeqcK3HOleTm5p7kjxMR8U96cjz3XzuK+68dydrqBi667z2emLuxU5z0PNkQnwFM9aanAq+EphwRkc7ripEFvHH7WZzRL4uf/n0l1zw6nw0+36M8mCGGTwPzgUFmVmFmNwK/BCaZ2TrgAm9eRCTq9cpI5omvnc5vrhrBmqoGJt//Pve9tZaDjc2+1GMd+ey5kpISV1ZW1mE/T0QknGrqD/KzV1fy6rJK+mSn8NPLT+PcQT1C/nPMbJFzruRYy3TFpojISerRPYkHvzyav9w4ltgY42t/Wsi0P5dRsbvjTnwqxEVE2unMgTm8fttZ/GDyIN5ft4ML7nmXh94u75AuFoW4iEgIJMTF8O1zinnrjrM555Qe/PqNNZzz63d4asEWGsM4tlwhLiISQgUZyfzh+jE8/Y1x5Gck8aOXPub8377L6qr6sPw8hbiISBiMH5DNizeX8r83lNA3J5XeWSlh+TlxYflWERHBzJg0JI9JQ8J3ZxIdiYuIRDCFuIhIBFOIi4hEMIW4iEgEU4iLiEQwhbiISARTiIuIRDCFuIhIBOvQW9GaWS2w+SQ/ngPsCGE5kUDb3DVom6Nfe7e3j3PumI9G69AQbw8zK/us++lGK21z16Btjn7h3F51p4iIRDCFuIhIBIukEH/U7wJ8oG3uGrTN0S9s2xsxfeIiIvLvIulIXEREjhIRIW5mk81sjZmVm9ldftdzssysyMzeNrOVZrbCzG7z2rPMbKaZrfPeM712M7MHvO1eZmajW33XVG/9dWY21a9tCpaZxZrZYjN71ZvvZ2YLvG171swSvPZEb77cW9631Xf80GtfY2YX+bQpQTGzDDN73sxWm9kqMxsf7fvZzL7n/btebmZPm1lStO1nM3vczGrMbHmrtpDtVzMbY2Yfe595wMyszaKcc536BcQC64H+QAKwFBjid10nuS35wGhvOg1YCwwBfgXc5bXfBdztTV8C/BMwYBywwGvPAjZ475nedKbf29fGtn8feAp41Zt/DrjWm/4DcLM3/W3gD970tcCz3vQQb98nAv28fxOxfm/XcbZ3OnCTN50AZETzfgYKgI1Acqv9+9Vo28/AWcBoYHmrtpDtV+BDb13zPntxmzX5/UsJ4pc2Hnij1fwPgR/6XVeItu0VYBKwBsj32vKBNd70I8CXWq2/xlv+JeCRVu2fWq+zvYBCYBZwHvCq9w90BxB39D4G3gDGe9Nx3np29H5vvV5newHpXqDZUe1Ru5+9EN/qBVOct58visb9DPQ9KsRDsl+9ZatbtX9qvc96RUJ3ypF/HEdUeG0RzfvzcRSwAMhzzlV6i6qAI89y+qxtj7TfyX3AD4Ajj/zOBuqcc03efOv6P9k2b/keb/1I2uZ+QC3wJ68L6TEzSyWK97NzbhvwG2ALUElgvy0iuvfzEaHarwXe9NHtxxUJIR51zKwb8AJwu3PuU4/AdoH/BUfNkCEz+xxQ45xb5HctHSiOwJ/cDzvnRgH7CPyZ/Yko3M+ZwBUE/gfWC0gFJvtalA/82K+REOLbgKJW84VeW0Qys3gCAf5X59yLXnO1meV7y/OBGq/9s7Y9kn4nE4DLzWwT8AyBLpX7gQwzO/Kg7tb1f7Jt3vJ0YCeRtc0VQIVzboE3/zyBUI/m/XwBsNE5V+ucawReJLDvo3k/HxGq/brNmz66/bgiIcQXAgO9s9wJBE6CzPC5ppPinWn+I7DKOXdPq0UzgCNnqKcS6Cs/0n6Dd5Z7HLDH+7PtDeBCM8v0joAu9No6HefcD51zhc65vgT23Wzn3HXA28AXvdWO3uYjv4sveus7r/1ab1RDP2AggZNAnY5zrgrYamaDvKbzgZVE8X4m0I0yzsxSvH/nR7Y5avdzKyHZr96yejMb5/0Ob2j1XZ/N75MEQZ5IuITASI71wH/4XU87tuNMAn9qLQOWeK9LCPQFzgLWAW8BWd76BjzkbffHQEmr7/o6UO69vub3tgW5/efwr9Ep/Qn8x1kO/A1I9NqTvPlyb3n/Vp//D+93sYYgztr7vK0jgTJvX79MYBRCVO9n4L+B1cBy4EkCI0yiaj8DTxPo828k8BfXjaHcr0CJ9/tbDzzIUSfHj/XSFZsiIhEsErpTRETkMyjERUQimEJcRCSCKcRFRCKYQlxEJIIpxEVEIphCXEQkginERUQi2P8H/7+tN5vywMYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7bef2",
   "metadata": {},
   "source": [
    "**CH5 합성곱 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbb27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate= 0.0002\n",
    "num_epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a40c0cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dataset.MNIST('./', train=True, transform=transforms.ToTensor(), target_transform=None,\\\n",
    "                           download=True)\n",
    "mnist_test = dataset.MNIST('./', train=False, transform=transforms.ToTensor(), target_transform=None,\\\n",
    "                          download=True)\n",
    "train_loader = DataLoader(mnist_train, batch_size= batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size= batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "#drop_last는 묶고 남은 데이터를 버릴지 결정하는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb1faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "234\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist_train))#train data 개수\n",
    "print(len(train_loader))#num of batches, not batch_size\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc98739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    x, y= data\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "213958a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 5., 3.]], dtype=torch.float64)\n",
      "tensor([[0.0900, 0.2447, 0.6652],\n",
      "        [0.0420, 0.8438, 0.1142]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[2,5,3]], dtype = torch.float64)\n",
    "print(x)\n",
    "m = nn.Softmax(dim=1)\n",
    "output = m(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28cb1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 모델 만들기\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                                   nn.Conv2d(1,16,5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(16,32,5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2,2),\n",
    "                                   nn.Conv2d(32,64,5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2,2))\n",
    "        self.fc = nn.Sequential(nn.Linear(3*3*64,512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512,100),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(100,10)\n",
    "                               )\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()#이 안에 이미 softmax가 구현되어 있음\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d376e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트셋에 대해 정화도 출력하는 함수\n",
    "def testloop(model, test_loader):\n",
    "    correct =0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            x = image.to(device)\n",
    "            y = label.to(device)\n",
    "            output=model(x)\n",
    "            _, pred = torch.max(output,axis=1)#가장 큰 값과 인덱스 반환\n",
    "            total += x.shape[0]\n",
    "            correct += torch.sum(pred==y)\n",
    "        print('Accuracy of Test Data:{}'.format(100*(correct/total)))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1db595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 loss: 0.22090481221675873\n",
      "Accuracy of Test Data:93.86017608642578\n",
      "epoch2 loss: 0.15422393381595612\n",
      "Accuracy of Test Data:96.55448913574219\n",
      "epoch3 loss: 0.06601164489984512\n",
      "Accuracy of Test Data:97.646240234375\n",
      "epoch4 loss: 0.08277162164449692\n",
      "Accuracy of Test Data:98.046875\n",
      "epoch5 loss: 0.04461143910884857\n",
      "Accuracy of Test Data:98.2772445678711\n",
      "epoch6 loss: 0.05688326060771942\n",
      "Accuracy of Test Data:98.5977554321289\n",
      "epoch7 loss: 0.05469166859984398\n",
      "Accuracy of Test Data:98.72796630859375\n",
      "epoch8 loss: 0.05410683527588844\n",
      "Accuracy of Test Data:98.93830108642578\n",
      "epoch9 loss: 0.017569834366440773\n",
      "Accuracy of Test Data:99.0184326171875\n",
      "epoch10 loss: 0.01642938330769539\n",
      "Accuracy of Test Data:99.13862609863281\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "loss_array = []\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    for j, [image,label] in enumerate(train_loader):\n",
    "        x = image.to(device) \n",
    "        y = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    loss_array.append(loss.data.cpu().detach().numpy())\n",
    "    print(f'epoch{i+1} loss: {loss.data}')\n",
    "    testloop(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b85f8ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_array)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aacf2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16애 필요한 블럭 리턴하는 함수 정의하기\n",
    "def conv_2_block(in_channels, out_channels):\n",
    "    model = nn.Sequential(\n",
    "                          nn.Conv2d(in_channels,out_channels,3,1,1),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(out_channels,out_channels,3,1,1),\n",
    "                          nn.ReLU(),\n",
    "                          nn.MaxPool2d(2,2))\n",
    "    return model\n",
    "\n",
    "def conv_3_block(in_channels,out_channels):\n",
    "    model = nn.Sequential(\n",
    "                          nn.Conv2d(in_channels,out_channels,3,1,1),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(out_channels,out_channels,3,1,1),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(out_channels,out_channels,3,1,1),\n",
    "                          nn.ReLU(),\n",
    "                          nn.MaxPool2d(2,2))\n",
    "    return model\n",
    "\n",
    "#VGG16\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self,input_channel, input_size, num_classes ):\n",
    "        super(VGG,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                                  conv_2_block(input_channel,64),\n",
    "                                  conv_2_block(64,128),\n",
    "                                  conv_3_block(128,256),\n",
    "                                  conv_3_block(256,512),\n",
    "                                  conv_3_block(512,512)\n",
    "                                 )\n",
    "        self.fc = nn.Sequential(nn.Linear(512*(input_size//32)*(input_size//32),4096),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(4096,4096),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(4096,1000),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(1000, num_classes)\n",
    "                               )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bcba179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (conv): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=32768, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1000, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG(3, 256, 10)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a2e8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인셉션모듈에 필요한 블럭 리턴하는 함수정의\n",
    "def conv1(in_channels,out_channels):\n",
    "    model = nn.Sequential(\n",
    "                          nn.Conv2d(in_channels, out_channels, 1),\n",
    "                          nn.ReLU()\n",
    "                         )\n",
    "    return model\n",
    "\n",
    "def conv1_3(in_channels, middle_channels, out_channels):\n",
    "    model = nn.Sequential(\n",
    "                          nn.Conv2d(in_channels, middle_channels, 1),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(middle_channels,out_channels, 3,1,1),\n",
    "                          nn.ReLU()\n",
    "                          )\n",
    "    return model\n",
    "\n",
    "def conv1_5(in_channels, middle_channels, out_channels):\n",
    "    model = nn.Sequential(\n",
    "                          nn.Conv2d(in_channels, middle_channels, 1),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(middle_channels,out_channels, 5,1,2),\n",
    "                          nn.ReLU()\n",
    "                          )\n",
    "    return model\n",
    "\n",
    "def pool3_conv1(in_channels, out_channels):\n",
    "    model = nn.Sequential(\n",
    "                          nn.MaxPool2d(3,1,1),\n",
    "                          nn.Conv2d(in_channels, out_channels, 1),\n",
    "                          nn.ReLU()\n",
    "                          )\n",
    "    return model\n",
    "\n",
    "#인셉션 모듈-> input_size는 변하지 않음\n",
    "class inception(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels1, middle_channels1,out_channels2, middle_channels2,\\\n",
    "                  out_channels3, out_channels4):\n",
    "        super(inception,self).__init__()\n",
    "        self.conv1 = conv1(in_channels, out_channels1)\n",
    "        self.conv1_3 = conv1_3(in_channels, middle_channels1, out_channels2)\n",
    "        self.conv1_5 = conv1_5(in_channels, middle_channels2, out_channels3)\n",
    "        self.pool3_conv1 = pool3_conv1(in_channels, out_channels4)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out1 = self.conv1(x)\n",
    "        out2 = self.conv1_3(x)\n",
    "        out3 = self.conv1_5(x)\n",
    "        out4 = self.pool3_conv1(x)\n",
    "        output = torch.cat([out1, out2, out3, out4], axis=1) #(batch_size, channel, H, W)이므로\n",
    "        return output\n",
    "\n",
    "#GoogLeNet\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, input_size, base_dim, num_classes=2):\n",
    "        super(GoogLeNet,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                                    nn.Conv2d(3,base_dim,7,2,3),\n",
    "                                    nn.MaxPool2d(3,2,1),\n",
    "                                    nn.Conv2d(base_dim,base_dim*3,3,1,1),\n",
    "                                    nn.MaxPool2d(3,2,1)\n",
    "                                   )#layer을 거치면, inputsize는 1/8됨\n",
    "        self.layer2 = nn.Sequential(\n",
    "                                     inception(base_dim*3, 64, 96, 128, 16, 32, 32 ),\n",
    "                                     inception(64+128+32+32, 128, 128, 192, 32, 96, 64),\n",
    "                                     nn.MaxPool2d(3,2,1))#layer2를 거치면, inputsize는 1/2가 됨\n",
    "        self.layer3 = nn.Sequential(\n",
    "                                    inception(480,192,96,208,16,48,64),\n",
    "                                    inception(512,160,112,224,24,64,64),\n",
    "                                    inception(512,128,128,256,24,64,64),\n",
    "                                    inception(512,112,144,288,32,64,64),\n",
    "                                    inception(528,256,160,320,32,128,128),\n",
    "                                    nn.MaxPool2d(3,2,1))#layer3를 거치면, inputsize는 1/2가 됨   \n",
    "        self.layer4 = nn.Sequential(\n",
    "                                    inception(832,256,160,320,32,128,128),\n",
    "                                    inception(832,384,192,384,48,128,128),\n",
    "                                    nn.AvgPool2d(7,1))#layer3를 거치면, inputsize-6이 됨\n",
    "        self.layer5 = nn.Dropout2d(0.4)\n",
    "        self.fc = nn.Linear(1024*(((input_size//32)-6)**2),num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x =self.layer1(x)\n",
    "        x =self.layer2(x)\n",
    "        x =self.layer3(x)\n",
    "        x =self.layer4(x)\n",
    "        x =self.layer5(x)\n",
    "        x =x.view(x.size(0), -1)\n",
    "        x =self.fc(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a77e6f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): inception(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1_3): Sequential(\n",
       "        (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (conv1_5): Sequential(\n",
       "        (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (pool3_conv1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  )\n",
       "  (layer5): Dropout2d(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GoogLeNet(256,32)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96e1634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottleblock에 필요한 블럭 리턴하는 함수\n",
    "def conv1(in_channels, out_channels, act_fn, stride=1):\n",
    "    model = nn.Sequential(nn.Conv2d(in_channels, out_channels,1, stride=stride),\n",
    "                          act_fn\n",
    "                         )\n",
    "    return model\n",
    "\n",
    "def conv3(in_channels, out_channels, act_fn):\n",
    "    model = nn.Sequential(nn.Conv2d(in_channels,out_channels,3,1,1),\n",
    "                          act_fn\n",
    "                         )\n",
    "    return model\n",
    "\n",
    "#bottleneck\n",
    "class bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, act_fn, down_sampling=False):\n",
    "        super(bottleneck,self).__init__()\n",
    "        self.act_fn = act_fn\n",
    "        self.down = down_sampling\n",
    "        if self.down:\n",
    "            self.conv= nn.Sequential(conv1(in_channels, middle_channels, act_fn,2),\n",
    "                      conv3(middle_channels,middle_channels,act_fn),\n",
    "                      conv1(middle_channels,out_channels,act_fn))\n",
    "            self.identity = nn.Conv2d(in_channels, out_channels, 1,2)\n",
    "        else:\n",
    "            self.conv= nn.Sequential(conv1(in_channels, middle_channels, act_fn,1),\n",
    "                      conv3(middle_channels,middle_channels,act_fn),\n",
    "                      conv1(middle_channels,out_channels,act_fn))\n",
    "            self.identity = nn.Conv2d(in_channels, out_channels,1)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        x = self.identity(x)\n",
    "        return out+x\n",
    "\n",
    "#ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_size, base_dim, num_classes=10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.act_fn = nn.ReLU()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                                    nn.Conv2d(3, base_dim,7,2,3),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(3,2,1)\n",
    "                                    )#input_size 1/4\n",
    "        self.layer2 = nn.Sequential(\n",
    "                                    bottleneck(base_dim,base_dim,base_dim*4,self.act_fn),\n",
    "                                    bottleneck(base_dim*4, base_dim, base_dim*4, self.act_fn),\n",
    "                                    bottleneck(base_dim*4, base_dim, base_dim*4, self.act_fn, \\\n",
    "                                               down_sampling=True)\n",
    "                                    )#input_size 1/2\n",
    "        self.layer3 = nn.Sequential(\n",
    "                                    bottleneck(base_dim*4, base_dim*2, base_dim*8, self.act_fn),\n",
    "                                    bottleneck(base_dim*8, base_dim*2, base_dim*8, self.act_fn),\n",
    "                                    bottleneck(base_dim*8, base_dim*2, base_dim*8, self.act_fn),\n",
    "                                    bottleneck(base_dim*8, base_dim*2, base_dim*8, self.act_fn, \\\n",
    "                                               down_sampling=True)\n",
    "                                    )#input_size 1/2\n",
    "        self.layer4 = nn.Sequential(\n",
    "                                    bottleneck(base_dim*8, base_dim*4, base_dim*16, self.act_fn),\n",
    "                                    bottleneck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
    "                                    bottleneck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
    "                                    bottleneck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
    "                                    bottleneck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
    "                                    bottleneck(base_dim*16, base_dim*4, base_dim*16, self.act_fn, \\\n",
    "                                               down_sampling=True)\n",
    "                                    )#input_size 1/2\n",
    "        self.layer5 = nn.Sequential(\n",
    "                                    bottleneck(base_dim*16, base_dim*8, base_dim*32, self.act_fn),\n",
    "                                    bottleneck(base_dim*32, base_dim*8, base_dim*32, self.act_fn),\n",
    "                                    bottleneck(base_dim*32, base_dim*8, base_dim*32, self.act_fn)\n",
    "                                    )\n",
    "        self.avgpool = nn.AvgPool2d(7,1)#input_size-6\n",
    "        self.fc = nn.Linear(base_dim*32*(((input_size//32)-6)**2),num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=self.layer5(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01032f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (act_fn): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (4): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (5): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): bottleneck(\n",
       "      (act_fn): ReLU()\n",
       "      (conv): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (identity): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=4096, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(256, 32)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
